---
title: Countering the Effects of Lead Bias in News Summarization via Multi-Stage Training
  and Auxiliary Losses
venue: Conference on Empirical Methods in Natural Language Processing
names: Matt Grenander, Yue Dong, J. Cheung, Annie Louis
tags:
- Conference on Empirical Methods in Natural Language Processing
link: https://arxiv.org/abs/1909.04028
author: Jackie Cheung
categories: Publications

---

*{{ page.names }}*

**{{ page.venue }}**

{% include display-publication-links.html pub=page %}

## Abstract

Sentence position is a strong feature for news summarization, since the lead often (but not always) summarizes the key points of the article. In this paper, we show that recent neural systems excessively exploit this trend, which although powerful for many inputs, is also detrimental when summarizing documents where important content should be extracted from later parts of the article. We propose two techniques to make systems sensitive to the importance of content in different parts of the article. The first technique employs ‘unbiased’ data; i.e., randomly shuffled sentences of the source document, to pretrain the model. The second technique uses an auxiliary ROUGE-based loss that encourages the model to distribute importance scores throughout a document by mimicking sentence-level ROUGE scores on the training data. We show that these techniques significantly improve the performance of a competitive reinforcement learning based extractive system, with the auxiliary loss being more powerful than pretraining.