---
title: Is BERT Robust to Label Noise? A Study on Learning with Noisy Labels in Text
  Classification
venue: First Workshop on Insights from Negative Results in NLP
names: D. Zhu, Michael A. Hedderich, Fangzhou Zhai, David Ifeoluwa Adelani, D. Klakow
tags:
- First Workshop on Insights from Negative Results in NLP
link: https://arxiv.org/abs/2204.09371
author: David Adelani
categories: Publications
layout: paper

---

*{{ page.names }}*

**{{ page.venue }}**

{% include display-publication-links.html pub=page %}

## Abstract

Incorrect labels in training data occur when human annotators make mistakes or when the data is generated via weak or distant supervision. It has been shown that complex noise-handling techniques - by modeling, cleaning or filtering the noisy instances - are required to prevent models from fitting this label noise. However, we show in this work that, for text classification tasks with modern NLP models like BERT, over a variety of noise types, existing noise-handling methods do not always improve its performance, and may even deteriorate it, suggesting the need for further investigation. We also back our observations with a comprehensive analysis.