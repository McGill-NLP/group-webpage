---
title: Investigating the Performance of Transformer-Based NLI Models on Presuppositional
  Inferences
venue: International Conference on Computational Linguistics
names: Jad Kabbara, J. Cheung
tags:
- International Conference on Computational Linguistics
link: https://www.semanticscholar.org/paper/90a35136bfdb158370cf5e7e6bc70fdb77fb5c8b
author: Jad Kabbara
categories: Publications

---

*{{ page.names }}*

**{{ page.venue }}**

{% include display-publication-links.html pub=page %}

## Abstract

Presuppositions are assumptions that are taken for granted by an utterance, and identifying them is key to a pragmatic interpretation of language. In this paper, we investigate the capabilities of transformer models to perform NLI on cases involving presupposition. First, we present simple heuristics to create alternative “contrastive” test cases based on the ImpPres dataset and investigate the model performance on those test cases. Second, to better understand how the model is making its predictions, we analyze samples from sub-datasets of ImpPres and examine model performance on them. Overall, our findings suggest that NLI-trained transformer models seem to be exploiting specific structural and lexical cues as opposed to performing some kind of pragmatic reasoning.