---
title: Using In-Context Learning to Improve Dialogue Safety
venue: ''
names: Nicholas Meade, Spandana Gella, Devamanyu Hazarika, Prakhar Gupta, Di Jin,
  Siva Reddy, Yang Liu, Dilek Z. Hakkani-Tür
tags:
- ''
link: https://arxiv.org/abs/2302.00871
author: Nicholas Meade
categories: Publications

---

*{{ page.names }}*

**{{ page.venue }}**

{% include display-publication-links.html pub=page %}

## Abstract

Warning: This paper contains examples that may be offensive or upsetting. While large neural-based conversational models have become increasingly proﬁcient as dialogue agents, recent work has highlighted safety issues with these systems. For example, these systems can be goaded into generating toxic content, which often perpetu-ates social biases or stereotypes. We investigate a retrieval-based framework for reducing bias and toxicity in responses generated from neural-based chatbots. It uses in-context learning to steer a model towards safer generations. Concretely, to generate a response to an unsafe dialogue context, we retrieve demonstrations of safe model responses to similar dialogue contexts. We ﬁnd our proposed approach performs competitively with strong baselines which use ﬁne-tuning. For instance, using automatic evaluation, we ﬁnd our best ﬁne-tuned baseline only generates safe responses to unsafe dialogue contexts from DiaSafety 2 . 92% more than our approach. Finally, we also propose a straightforward re-ranking procedure which can further improve response safeness.