---
title: Using In-Context Learning to Improve Dialogue Safety
venue: EMNLP Findings
names: Nicholas Meade, Spandana Gella, Devamanyu Hazarika, Prakhar Gupta, Di Jin,
  Siva Reddy, Yang Liu, Dilek Z. Hakkani-TÃ¼r
tags:
- EMNLP
link: https://arxiv.org/abs/2302.00871
twitter: https://x.com/ncmeade/status/1661178058554867714
thumbnail: /assets/images/papers/icl-dialogue-safety.png
author: Nicholas Meade
categories: Publications

---

*{{ page.names }}*

**{{ page.venue }}**

{% include display-publication-links.html pub=page %}

## Abstract

While large neural-based conversational models have become increasingly proficient dialogue agents, recent work has highlighted safety issues with these systems. For example, these systems can be goaded into generating toxic content, which often perpetuates social biases or stereotypes. We investigate a retrieval-based method for reducing bias and toxicity in responses from chatbots. It uses in-context learning to steer a model towards safer generations. Concretely, to generate a response to an unsafe dialogue context, we retrieve demonstrations of safe responses to similar dialogue contexts. We find our method performs competitively with strong baselines without requiring training. For instance, using automatic evaluation, we find our best fine-tuned baseline only generates safe responses to unsafe dialogue contexts from DiaSafety 4.04% more than our approach. Finally, we also propose a re-ranking procedure which can further improve response safeness.
