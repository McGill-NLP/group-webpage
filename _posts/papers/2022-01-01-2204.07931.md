---
title: 'On the Origin of Hallucinations in Conversational Models: Is it the Datasets
  or the Models?'
venue: NAACL
names: Nouha Dziri, Sivan Milton, Mo Yu, Osmar R Zaiane, Siva Reddy
tags:
- NAACL
link: https://arxiv.org/abs/2204.07931
author: Siva Reddy
categories: Publications
layout: paper
---

*{{ page.names }}*

**{{ page.venue }}**

{% include display-publication-links.html pub=page %}

## Abstract

Knowledge-grounded conversational models are known to suffer from producing factually invalid statements, a phenomenon commonly called hallucination. In this work, we investigate the underlying causes of this phenomenon: is hallucination due to the training data, or to the models? We conduct a comprehensive human study on both existing knowledge-grounded conversational benchmarks and several state-of-the-art models. Our study reveals that the standard benchmarks consist of > 60% hallucinated responses, leading to models that not only hallucinate but even amplify hallucinations. Our Ô¨Åndings raise important questions on the quality of existing datasets and models trained using them. We make our annotations publicly available for future research. 1
