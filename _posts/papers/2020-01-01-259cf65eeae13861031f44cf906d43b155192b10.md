---
author: Siva Reddy
categories: Publications
link: https://www.semanticscholar.org/paper/259cf65eeae13861031f44cf906d43b155192b10
names: Yikang Shen, Shawn Tan, Alessandro Sordoni, Siva Reddy, Aaron C. Courville
tags:
- ArXiv
title: Explicitly Modeling Syntax in Language Model improves Generalization
venue: ArXiv 2020

---

*{{ page.names }}*

**{{ page.venue }}**

{% include display-publication-links.html pub=page%}

## Abstract

Syntax is fundamental to our thinking about language. Although neural networks are very successful in many tasks, they do not explicitly model syntactic structure. Failing to capture the structure of inputs could lead to generalization problems and over-parametrization. In the present work, we propose a new syntax-aware language model: Syntactic Ordered Memory (SOM). The model explicitly models the structure with a one-step look-ahead parser and maintains the conditional probability setting of the standard language model. Experiments show that SOM can achieve strong results in language modeling and syntactic generalization tests, while using fewer parameters then other models.