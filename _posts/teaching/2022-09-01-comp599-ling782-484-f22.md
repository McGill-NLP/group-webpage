---
title: Natural Language Understanding with Deep Learning / Computational Semantics
term: Fall 2022
course_code: COMP 599; LING 484/782
author: Siva Reddy
names: Siva Reddy
categories: Teaching
share: false
last_modified_at: 2022-08-30T00:00:00
layout: single
toc: true
toc_sticky: true
toc_label: "Table of Contents"
tags:
  - Fall 2022
---

* **Course Code:** COMP 599 & LING 484/782 (Fall 2022)
* **Instructor**: [Siva Reddy](https://sivareddy.in/)
* **Teaching Assistants**: [Aristides Milios](http://atmilios.com/), [Nicholas Meade](https://ncmeade.github.io/), [Xing Han Lu](https://xinghanlu.com/)
* **Classroom**: ENGMD 280, [McConnell Engineering Building](https://www.mcgill.ca/engineering/faculty-staff/buildings-facilities/buildings-facilities-directory/mcconnell)
* **Time**: Tuesday and Thursdays, 10:05 AM to 11:25 AM
* **Links**: [MyCourses](https://mycourses2.mcgill.ca/d2l/home/599705)

# Description

The field of natural language processing (NLP) has seen multiple paradigm shifts over decades, from symbolic AI to statistical methods to deep learning. We review this shift through the lens of natural language understanding (NLU), a branch of NLP that deals with “meaning”. We start with what is meaning and what does it mean for a machine to understand language? We explore how to represent the meaning of words, phrases, sentences and discourse. We then dive into many useful NLU applications. 

Throughout the course, we take several concepts in NLU such as meaning or applications such as question answering, and study how the paradigm has shifted, what we gained with each paradigm shift, and what we lost? We will critically evaluate existing ideas and try to come up with new ideas that challenge existing limitations. We will particularly work on making deep learning models for language more robust.

# Prerequisites

You are expected to have done one of the following courses at McGill: natural language processing (COMP/LING 550) or computational linguistics (COMP/LING 445) or applied machine learning (COMP 551). If you have done similar courses at other universities, feel free to take the course. If you are not sure, email the instructor.

# Grading

Assignments (60%): Automatic grading + written report
1. Basics of deep learning and neural networks for NLP (15%)
2. word2vec and word representation (15%)
3. Char-RNN and ELMo (15%)
4. Transformers and applications (15%)

Project (35%): You will do a project in groups of two.
* Proposal (5%)
* Presentation (5%)
* Final report (25%)

Participation (5%): Class participation amongst other things. Details to be determined.

# Topics (Tentative)

| Topic | Subtopics | | | |
| --- | --- | --- | --- | --- |
| Word meaning | distributional semantics | word embeddings | evaluation | |
| Phrase and sentence meaning | logical representation | sentence embeddings | evaluation | |
| Meaning in context | word senses | contextual word embeddings | fine-tuning | |
| Interpretability | feature-based vs deep learning models | linguistic tests | probing | |
| Compositionality | syntax and semantic interfaces | inductive priors | tests for compositionality | limitations |
| Reasoning | inference | question answering | other applications | |
| Discourse | conversational systems | | | |
| Language and physical world | model-theoretic semantics | grounded environment | reinforcement learning | |
| Bias | word association tests | probing | | |

# Schedule

| Lecture | Date                 | Topic        | Additional Readings |
| ------- | -------------------- | ------------ | ------------------- |
| 1       | Sep 1                |              |                     |
| 2       | Sep 6                |              |                     |
| 3       | Sep 8                |              |                     |
| 4       | Sep 13 (add or drop) |              |                     |
| 5       | Sep 15               |              |                     |
| 6       | Sep 20               |              |                     |
| 7       | Sep 22               |              |                     |
| 8       | Sep 27               |              |                     |
| 9       | Sep 29               |              |                     |
| 10      | Oct 4                |              |                     |
| 11      | Oct 6                |              |                     |
| 12      | Oct 11               | Reading week |                     |
| 13      | Oct 13               | No Lecture   |                     |
| 14      | Oct 18               |              |                     |
| 15      | Oct 20               |              |                     |
| 16      | Oct 25               |              |                     |
| 17      | Oct 27               |              |                     |
| 18      | Nov 1                |              |                     |
| 19      | Nov 3                |              |                     |
| 20      | Nov 8                |              |                     |
| 21      | Nov 10               |              |                     |
| 22      | Nov 15               |              |                     |
| 23      | Nov 17               |              |                     |
| 24      | Nov 22               |              |                     |
| 25      | Nov 24               |              |                     |
| 26      | Nov 29               |              |                     |
| 27      | Dec 1                |              |                     |


# FAQs

**Question:** What are some books for learning basics of linguistics?  
[Bender 2013: Linguistic Fundamentals for Natural Language Processing (login with McGill credentials for free access)](https://mcgill.on.worldcat.org/oclc/853273078))  

**Question:** What are some books books on deep learning for NLP?  
[Jurafsky and Martin 2019: Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/)  
[Tunstall et al. 2022: Natural Language Processing with Transformers (login with McGill credentials)](
https://mcgill.on.worldcat.org/oclc/1321899597)  
[Eisenstein 2019: Introduction to Natural Language Processing](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf)  
[Goldberg 2017: Neural Network Methods for Natural Language Processing (login with McGill credentials)](https://mcgill.on.worldcat.org/oclc/982699889)  

# Language of Submission

In accord with McGill University’s Charter of Students’ Rights, students in this course have the right to submit in English or in French any written work that is to be graded. 

# Academic Integrity

McGill University values academic integrity. Therefore, all students must understand the meaning and consequences of cheating, plagiarism and other academic offences under the Code of Student Conduct and Disciplinary Procedures (see www.mcgill.ca/students/srr/honest/ for more information)

# Inclusivity
As the instructor of this course I endeavor to provide an inclusive learning environment. However, if you experience barriers to learning in this course, do not hesitate to discuss them with me or the Office for Students with Disabilities.
